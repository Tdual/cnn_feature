{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "downlaod from fashonMNIST  \n",
    "put downloaded data into data/fashion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/fashion/train-images-idx3-ubyte.gz\n",
      "Extracting ./data/fashion/train-labels-idx1-ubyte.gz\n",
      "Extracting ./data/fashion/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./data/fashion/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('./data/fashion', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = mnist.train.next_batch(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABIEAAACBCAYAAABXearSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgArARyAAAAAAAAAAgArw//PKBRDrgItuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1d200ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dim = 28\n",
    "fig, axs = plt.subplots(1, len(img), figsize=(20, 3))\n",
    "for i, m in enumerate(img):\n",
    "        axs[i].imshow(np.reshape(m, (dim, dim)),cmap='gray')\n",
    "        axs[i].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    w = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(w)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    b = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(b)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "def variable_summaries(var):\n",
    "   \n",
    "    with tf.name_scope('summaries'):\n",
    "        mean = tf.reduce_mean(var)\n",
    "        tf.summary.scalar('mean', mean)\n",
    "        with tf.name_scope('stddev'):\n",
    "            stddev = tf.sqrt(tf.reduce_mean(tf.square(var - mean)))\n",
    "        tf.summary.scalar('stddev', stddev)\n",
    "        tf.summary.scalar('max', tf.reduce_max(var))\n",
    "        tf.summary.scalar('min', tf.reduce_min(var))\n",
    "        tf.summary.histogram('histogram', var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = 28 * 28\n",
    "log_dir = \"./logs\"\n",
    "\n",
    "with tf.name_scope('input'):\n",
    "    x = tf.placeholder(tf.float32, shape=[None, 784], name='x-input')\n",
    "    y_ = tf.placeholder(tf.float32, shape=[None, 10], name='y-input')\n",
    "\n",
    "with tf.name_scope('input_reshape'):    \n",
    "    x_image = tf.reshape(x, [-1, 28, 28, 1])\n",
    "    tf.summary.image('input',  x_image, 10)\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    with tf.name_scope('weights'):\n",
    "        W_conv1 = weight_variable([5,5,1,32])\n",
    "        variable_summaries(W_conv1)        \n",
    "    with tf.name_scope('biases'):\n",
    "        b_conv1 = bias_variable([32])\n",
    "        variable_summaries(b_conv1)\n",
    "        \n",
    "with tf.name_scope(\"conv1\"):\n",
    "    h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "    variable_summaries(h_conv1)\n",
    "\n",
    "with tf.name_scope(\"pool1\"):   \n",
    "    h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "with tf.name_scope(\"layer1\"):\n",
    "    with tf.name_scope('weights'):\n",
    "        W_conv2 = weight_variable([5,5,32,64])\n",
    "    with tf.name_scope('biases'):    \n",
    "        b_conv2 = bias_variable([64])\n",
    "\n",
    "with tf.name_scope(\"conv2\"):\n",
    "    h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "\n",
    "with tf.name_scope(\"pool2\"):\n",
    "    h_pool2 = max_pool_2x2(h_conv2)\n",
    "    \n",
    "with tf.name_scope(\"pool2_flat\"):\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    with tf.name_scope('weights'):\n",
    "        W_fc1 = weight_variable([7 * 7 * 64, 1024])\n",
    "    with tf.name_scope('biases'):   \n",
    "        b_fc1 = bias_variable([1024])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "with tf.name_scope(\"dropout\"):\n",
    "    keep_prob = tf.placeholder(tf.float32)\n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "with tf.name_scope(\"fc2\"):\n",
    "    W_fc2 = weight_variable([1024,10])\n",
    "    b_fc2 = bias_variable([10])\n",
    "\n",
    "with tf.name_scope(\"output\"):\n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "with tf.name_scope(\"loss\"):\n",
    "    loss = tf.reduce_mean(\n",
    "        tf.nn.softmax_cross_entropy_with_logits(labels=y_, logits=y_conv))\n",
    "    tf.summary.scalar('cross_entropy', loss)\n",
    "\n",
    "\n",
    "with tf.name_scope(\"opt\"):\n",
    "    opt = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"accuracy\"):\n",
    "    correct = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    tf.summary.scalar('accuracy', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training loss 4.21984, training accuracy 0.14\n",
      "step 100, training loss 0.87452, training accuracy 0.7\n",
      "step 200, training loss 0.568433, training accuracy 0.82\n",
      "step 300, training loss 0.554546, training accuracy 0.84\n",
      "step 400, training loss 0.547397, training accuracy 0.82\n",
      "step 500, training loss 0.447093, training accuracy 0.82\n",
      "step 600, training loss 0.328532, training accuracy 0.92\n",
      "step 700, training loss 0.369603, training accuracy 0.82\n",
      "step 800, training loss 0.353002, training accuracy 0.92\n",
      "step 900, training loss 0.402721, training accuracy 0.9\n",
      "step 1000, training loss 0.310463, training accuracy 0.9\n",
      "step 1100, training loss 0.415666, training accuracy 0.82\n",
      "step 1200, training loss 0.333423, training accuracy 0.94\n",
      "step 1300, training loss 0.212392, training accuracy 0.96\n",
      "step 1400, training loss 0.255833, training accuracy 0.9\n",
      "step 1500, training loss 0.501838, training accuracy 0.84\n",
      "step 1600, training loss 0.462665, training accuracy 0.84\n",
      "step 1700, training loss 0.261405, training accuracy 0.9\n",
      "step 1800, training loss 0.445338, training accuracy 0.86\n",
      "step 1900, training loss 0.338297, training accuracy 0.88\n",
      "test accuracy 0.8673\n"
     ]
    }
   ],
   "source": [
    "if tf.gfile.Exists(log_dir):\n",
    "    tf.gfile.DeleteRecursively(log_dir)\n",
    "tf.gfile.MakeDirs(log_dir)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    merged = tf.summary.merge_all()\n",
    "    train_writer = tf.summary.FileWriter(log_dir + '/train', sess.graph)\n",
    "    test_writer = tf.summary.FileWriter(log_dir + '/test')\n",
    "    \n",
    "    for i in range(2000):\n",
    "        batch = mnist.train.next_batch(50)\n",
    "        opt.run(feed_dict={x: batch[0], y_: batch[1], keep_prob: 0.5})\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            train_loss, train_accuracy, summary = sess.run([loss, accuracy, merged], feed_dict={\n",
    "                  x: batch[0], y_: batch[1], keep_prob: 1.0})\n",
    "            print('step %d, training loss %g, training accuracy %g' % (i, train_loss, train_accuracy))\n",
    "            train_writer.add_summary(summary, i)\n",
    "        \n",
    "    test_accuracy, test_summary = sess.run([accuracy, merged], \n",
    "                                           feed_dict={x: mnist.test.images, y_: mnist.test.labels, keep_prob: 1.0})\n",
    "    train_writer.add_summary(test_summary, 0)\n",
    "    print('test accuracy %g' % test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'./logs/model.ckpt-1'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "xs = mnist.test.images\n",
    "\n",
    "embedding_var = tf.Variable(xs, name='embedding')\n",
    "summary_writer = tf.summary.FileWriter(log_dir)\n",
    "\n",
    "config = projector.ProjectorConfig()\n",
    "embedding = config.embeddings.add()\n",
    "embedding.tensor_name = embedding_var.name\n",
    "\n",
    "embedding.metadata_path = os.path.join(log_dir, 'metadata.tsv')\n",
    "\n",
    "embedding.sprite.image_path = os.path.join(log_dir, 'sprite_image.png')\n",
    "embedding.sprite.single_image_dim.extend([28,28])\n",
    "\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, os.path.join(log_dir, \"model.ckpt\"), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.tsv','w') as f:\n",
    "    f.write(\"Index\\tLabel\\n\")\n",
    "    for index, label in enumerate(mnist.test.labels):\n",
    "        f.write(\"%d\\t%d\\n\" % (index, label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding.sprite.single_image_dim.extend([28,28])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 784)\n",
      "100\n",
      "100\n",
      "(100, 78400)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape must be rank 3 but is rank 2 for 'EncodeJpeg_6' (op: 'EncodeJpeg') with input shapes: [100,78400].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    653\u001b[0m           \u001b[0mgraph_def_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnode_def_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m           input_tensors_as_shapes, status)\n\u001b[0m\u001b[1;32m    655\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape must be rank 3 but is rank 2 for 'EncodeJpeg_6' (op: 'EncodeJpeg') with input shapes: [100,78400].",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-447a3ae44dd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mjpeg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_jpeg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjpeg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/ops/gen_image_ops.py\u001b[0m in \u001b[0;36mencode_jpeg\u001b[0;34m(image, format, quality, progressive, optimize_size, chroma_downsampling, density_unit, x_density, y_density, xmp_metadata, name)\u001b[0m\n\u001b[1;32m    486\u001b[0m                                 \u001b[0mdensity_unit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdensity_unit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m                                 \u001b[0mx_density\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx_density\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_density\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_density\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m                                 xmp_metadata=xmp_metadata, name=name)\n\u001b[0m\u001b[1;32m    489\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36mapply_op\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    765\u001b[0m         op = g.create_op(op_type_name, inputs, output_types, name=scope,\n\u001b[1;32m    766\u001b[0m                          \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattr_protos\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 767\u001b[0;31m                          op_def=op_def)\n\u001b[0m\u001b[1;32m    768\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_structure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcreate_op\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_shapes, compute_device)\u001b[0m\n\u001b[1;32m   2630\u001b[0m                     original_op=self._default_original_op, op_def=op_def)\n\u001b[1;32m   2631\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcompute_shapes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2632\u001b[0;31m       \u001b[0mset_shapes_for_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2633\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2634\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_op_seen_by_control_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mset_shapes_for_outputs\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1909\u001b[0m       \u001b[0mshape_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1910\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1911\u001b[0;31m   \u001b[0mshapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshape_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1912\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshapes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1913\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcall_with_requiring\u001b[0;34m(op)\u001b[0m\n\u001b[1;32m   1859\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1860\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcall_cpp_shape_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequire_shape_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1862\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1863\u001b[0m   \u001b[0m_call_cpp_shape_fn_and_require_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_with_requiring\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36mcall_cpp_shape_fn\u001b[0;34m(op, require_shape_fn)\u001b[0m\n\u001b[1;32m    593\u001b[0m     res = _call_cpp_shape_fn_impl(op, input_tensors_needed,\n\u001b[1;32m    594\u001b[0m                                   \u001b[0minput_tensors_as_shapes_needed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m                                   require_shape_fn)\n\u001b[0m\u001b[1;32m    596\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m       \u001b[0;31m# Handles the case where _call_cpp_shape_fn_impl calls unknown_shape(op).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/py3.6/lib/python3.6/site-packages/tensorflow/python/framework/common_shapes.py\u001b[0m in \u001b[0;36m_call_cpp_shape_fn_impl\u001b[0;34m(op, input_tensors_needed, input_tensors_as_shapes_needed, require_shape_fn)\u001b[0m\n\u001b[1;32m    657\u001b[0m       \u001b[0mmissing_shape_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 659\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    661\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mmissing_shape_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape must be rank 3 but is rank 2 for 'EncodeJpeg_6' (op: 'EncodeJpeg') with input shapes: [100,78400]."
     ]
    }
   ],
   "source": [
    "images = mnist.test.images\n",
    "print(images.shape)\n",
    "size = int(np.sqrt(len(images)))\n",
    "print(size)\n",
    "rows = []\n",
    "with tf.Session() as sess:\n",
    "    images = tf.cast(mnist.test.images, tf.uint8)\n",
    "    for i, img in enumerate(images):\n",
    "        image = tf.reshape(img, [-1, 28, 28, 1])\n",
    "        rows.append(tf.concat(images[i*size: (i+1)*size],1))\n",
    "    print(len(rows))\n",
    "    j = sess.run(tf.concat(rows, 1))\n",
    "    print(j.shape)\n",
    "    #jpeg = tf.image.encode_jpeg(tf.concat(rows, 0))\n",
    "    for img in images:\n",
    "        image = tf.reshape(img, [-1, 28, 28, 1])\n",
    "        \n",
    "    sprit = tf.reshape(images, [])\n",
    "    jpeg = tf.image.encode_jpeg(sprit)\n",
    "    with open(image_path, 'wb') as f:\n",
    "        f.write(sess.run(jpeg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for idx, img in enumerate(mnist.test.images):\n",
    "    np.reshape(m, (dim, dim,1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#thumbnail = tf.cast(tf.image.resize_images(tf.image.decode_jpeg(jpeg_data), [100, 100]), tf.uint8)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_py3.6)",
   "language": "python",
   "name": "conda_py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
